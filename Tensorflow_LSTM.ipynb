{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "print(mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr = 1e-3\n",
    "input_size = 28      # 每个时刻的输入特征是28维的，就是每个时刻输入一行，一行有 28 个像素\n",
    "timestep_size = 28   # 时序持续长度为28，即每做一次预测，需要先输入28行\n",
    "hidden_size = 256    # 隐含层的数量\n",
    "layer_num = 2        # LSTM layer 的层数\n",
    "class_num = 10       # 最后输出分类类别数量，如果是回归预测的话应该是 1\n",
    "\n",
    "_X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, class_num])\n",
    "# 在训练和测试的时候，我们想用不同的 batch_size.所以采用占位符的方式\n",
    "batch_size = tf.placeholder(tf.int32, [])  # 注意类型必须为 tf.int32, batch_size = 128\n",
    "keep_prob = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把784个点的字符信息还原成 28 * 28 的图片\n",
    "# 下面几个步骤是实现 RNN / LSTM 的关键\n",
    "####################################################################\n",
    "# **步骤1：RNN 的输入shape = (batch_size, timestep_size, input_size) \n",
    "X = tf.reshape(_X, [-1, 28, 28])\n",
    "\n",
    "# # **步骤2：定义一层 LSTM_cell，只需要说明 hidden_size, 它会自动匹配输入的 X 的维度\n",
    "# lstm_cell = rnn.BasicLSTMCell(num_units=hidden_size, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "# # **步骤3：添加 dropout layer, 一般只设置 output_keep_prob\n",
    "# lstm_cell = rnn.DropoutWrapper(cell=lstm_cell, input_keep_prob=1.0, output_keep_prob=keep_prob)\n",
    "\n",
    "# # **步骤4：调用 MultiRNNCell 来实现多层 LSTM\n",
    "# mlstm_cell = rnn.MultiRNNCell([lstm_cell] * layer_num, state_is_tuple=True)\n",
    "# mlstm_cell = rnn.MultiRNNCell([lstm_cell for _ in range(layer_num)] , state_is_tuple=True)\n",
    "\n",
    "# 在 tf 1.0.0 版本中，可以使用上面的 三个步骤创建多层 lstm， 但是在 tf 1.2.1 版本中，可以通过下面方式来创建\n",
    "def lstm_cell():\n",
    "    cell = rnn.LSTMCell(hidden_size, reuse=tf.get_variable_scope().reuse)\n",
    "    return rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "\n",
    "mlstm_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)], state_is_tuple = True)\n",
    "\n",
    "# **步骤5：用全零来初始化state\n",
    "init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# **步骤6：方法一，调用 dynamic_rnn() 来让我们构建好的网络运行起来\n",
    "# ** 当 time_major==False 时， outputs.shape = [batch_size, timestep_size, hidden_size] \n",
    "# ** 所以，可以取 h_state = outputs[:, -1, :] 作为最后输出\n",
    "# ** state.shape = [layer_num, 2, batch_size, hidden_size], \n",
    "# ** 或者，可以取 h_state = state[-1][1] 作为最后输出\n",
    "# ** 最后输出维度是 [batch_size, hidden_size]\n",
    "outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, initial_state=init_state, time_major=False)\n",
    "h_state = state[-1][1]\n",
    "\n",
    "# *************** 为了更好的理解 LSTM 工作原理，我们把上面 步骤6 中的函数自己来实现 ***************\n",
    "# 通过查看文档你会发现， RNNCell 都提供了一个 __call__()函数，我们可以用它来展开实现LSTM按时间步迭代。\n",
    "# **步骤6：方法二，按时间步展开计算\n",
    "# outputs = list()\n",
    "# state = init_state\n",
    "# with tf.variable_scope('RNN'):\n",
    "#     for timestep in range(timestep_size):\n",
    "#         if timestep > 0:\n",
    "#             tf.get_variable_scope().reuse_variables()\n",
    "#         # 这里的state保存了每一层 LSTM 的状态\n",
    "#         (cell_output, state) = mlstm_cell(X[:, timestep, :],state)\n",
    "#         outputs.append(cell_output)\n",
    "# h_state = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter5, step 200, training accuracy 0.9375\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter5, step 400, training accuracy 0.976562\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter6, step 600, training accuracy 0.96875\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter6, step 800, training accuracy 0.984375\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter6, step 1000, training accuracy 0.984375\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter7, step 1200, training accuracy 0.984375\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter7, step 1400, training accuracy 0.984375\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter8, step 1600, training accuracy 0.992188\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter8, step 1800, training accuracy 0.984375\n",
      "Tensor(\"Softmax_1:0\", shape=(?, 10), dtype=float32)\n",
      "(128, 784)\n",
      "Iter9, step 2000, training accuracy 0.992188\n",
      "test accuracy 0.9863\n"
     ]
    }
   ],
   "source": [
    "W=tf.Variable(tf.truncated_normal([hidden_size,class_num],stddev=0.1),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.constant(0.1,shape=[class_num]),dtype=tf.float32)\n",
    "y_pred=tf.nn.softmax(tf.matmul(h_state,W)+bias)\n",
    "cross_entropy=-tf.reduce_mean(y*tf.log(y_pred))\n",
    "train_op=tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2000):\n",
    "    _batch_size=128\n",
    "    batch=mnist.train.next_batch(_batch_size)\n",
    "    if (i+1)%200 ==0:\n",
    "        train_accuracy=sess.run(accuracy,feed_dict={\n",
    "            _X:batch[0],y:batch[1],keep_prob:1.0,batch_size:_batch_size\n",
    "        })\n",
    "        print(y_pred)\n",
    "        print(batch[0].shape)\n",
    "        print(\"Iter%d, step %d, training accuracy %g\" % (mnist.train.epochs_completed,(i+1),train_accuracy))\n",
    "    sess.run(train_op,feed_dict={_X:batch[0],y:batch[1],keep_prob:0.5,batch_size:_batch_size})\n",
    "print(\"test accuracy %g\"% sess.run(accuracy,feed_dict={\n",
    "    _X:mnist.test.images,y:mnist.test.labels,keep_prob:1.0,batch_size:mnist.test.images.shape[0]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784) (5, 10)\n",
      "outputs.shape= (5, 28, 256)\n",
      "arr_state.shape= (2, 2, 5, 256)\n",
      "[[-0.29114476 -0.84908068 -0.02608863 ..., -0.26059726 -0.41139302\n",
      "   0.59013247]\n",
      " [-0.6596756   0.1405973   0.32068741 ...,  0.78834546 -0.85109633\n",
      "  -0.55030227]\n",
      " [ 0.91946286 -0.6195702   0.00405734 ...,  0.50050467  0.4910633\n",
      "  -0.59666592]\n",
      " [-0.89336431  0.21388607  0.50573528 ...,  0.75225669  0.6082601\n",
      "  -0.56074399]\n",
      " [-0.36205587 -0.87424242  0.77999097 ...,  0.395004   -0.788903\n",
      "  -0.25867409]]\n",
      "[[ 0.02811883 -0.1008996   0.03933555 ..., -0.26678833 -0.0076026\n",
      "  -0.04358114]\n",
      " [-0.27545795  0.08285692 -0.09781252 ..., -0.40972584  0.14314541\n",
      "   0.83173752]\n",
      " [-0.21126685  0.08805162  0.52263641 ..., -0.16019027  0.06584492\n",
      "   0.14457463]\n",
      " [ 0.10716452  0.02429411  0.23363011 ...,  0.07705231  0.1158627\n",
      "   0.38137382]\n",
      " [ 0.10278453 -0.19593915  0.18716493 ..., -0.15240444 -0.24707885\n",
      "   0.18361446]]\n"
     ]
    }
   ],
   "source": [
    "_batch_size=5\n",
    "X_batch,y_batch=mnist.test.next_batch(_batch_size)\n",
    "print(X_batch.shape,y_batch.shape)\n",
    "_outputs,_state=sess.run([outputs,state],feed_dict={\n",
    "    _X:X_batch,y:y_batch,keep_prob:1.0,batch_size:_batch_size\n",
    "})\n",
    "print('outputs.shape=',np.asarray(_outputs).shape)\n",
    "print('arr_state.shape=',np.asarray(_state).shape)\n",
    "\n",
    "print(np.asarray(_state[-1][1]))\n",
    "print(np.asarray(_state[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132c7320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X3=mnist.train.images[3]\n",
    "img3=X3.reshape([28,28])\n",
    "print(img3.shape)\n",
    "plt.imshow(img3,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 256)\n",
      "(28, 256)\n"
     ]
    }
   ],
   "source": [
    "X3.shape=[-1,784]\n",
    "y_batch=mnist.train.labels[0]\n",
    "y_batch.shape=[-1,class_num]\n",
    "\n",
    "X3_outputs=np.array(sess.run(outputs,feed_dict={\n",
    "    _X:X3,y:y_batch,keep_prob:1.0,batch_size:1\n",
    "}))\n",
    "print(X3_outputs.shape)\n",
    "X3_outputs.shape=[28,hidden_size]\n",
    "print(X3_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08456483  0.08745969 -0.07621165 ..., -0.00773322 -0.15107249\n",
      "   0.10566489]\n",
      " [ 0.26069802  0.13171725  0.0247799  ...,  0.08384562  0.06285298\n",
      "   0.03339371]\n",
      " [-0.02133826 -0.08564553  0.09821648 ...,  0.05742728  0.02910433\n",
      "   0.17623523]\n",
      " ..., \n",
      " [ 0.14126052  0.15447645 -0.08539373 ..., -0.27805188  0.12536794\n",
      "   0.0209918 ]\n",
      " [-0.11653625  0.07422358  0.14709686 ..., -0.03686545  0.01324715\n",
      "  -0.12571484]\n",
      " [-0.14584878  0.00623576  0.01669303 ...,  0.08890152 -0.1124042\n",
      "  -0.15828955]]\n",
      "[ 0.0999197   0.14981271  0.07992077  0.08728788  0.08243027  0.11954871\n",
      "  0.08033348  0.12624525  0.10010903  0.08718728]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4gRfoAY4QeI+R+OpX87Hvo8hgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13822240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_W=sess.run(W,feed_dict={\n",
    "    _X:X3,y:y_batch,keep_prob:1.0,batch_size:1\n",
    "})\n",
    "print(h_W)\n",
    "h_bias=sess.run(bias,feed_dict={\n",
    "    _X:X3,y:y_batch,keep_prob:1.0,batch_size:1\n",
    "})\n",
    "print(h_bias)\n",
    "bar_index=range(class_num)\n",
    "for i in range(X3_outputs.shape[0]):\n",
    "    plt.subplot(7,4,i+1)\n",
    "    x3_h_shate=X3_outputs[i,:].reshape([-1,hidden_size])\n",
    "    pro=sess.run(tf.nn.softmax(tf.matmul(x3_h_shate,h_W)+h_bias))\n",
    "    plt.bar(bar_index,pro[0],width=0.2,align='center')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
